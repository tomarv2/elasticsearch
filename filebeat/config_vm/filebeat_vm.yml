kafka.home: /opt/kafka
zk.home: /opt/zookeeper

filebeat.prospectors:
- type: log
  # kafka log files prospector
  paths:
    - ${kafka.home}/logs/server.log*
  # match multiline events
  multiline.pattern: '^\['
  multiline.negate: true
  multiline.match: after
  # configure pipeline
  fields.pipeline: kafka-logs

- type: log
  # kafka gc log prospector
  paths:
    - ${kafka.home}/logs/kafkaServer-gc.log
  # match multiline events
  multiline.pattern: '^\s'
  multiline.negate: false
  multiline.match: after
  # include only 'GC pause' stats
  include_lines: ['GC pause']
  # configure pipeline
  fields.pipeline: kafka-gc-logs

- type: log
  # kafka gc log prospector
  paths:
    - ${zk.home}/logs/kafkaServer-gc.log
  # match multiline events
  multiline.pattern: '^\s'
  multiline.negate: false
  multiline.match: after
  # include only 'GC pause' stats
  include_lines: ['GC pause']
  # configure pipeline
  fields.pipeline: kafka-gc-logs


output:
  elasticsearch:
    hosts: ["es.test.xyz.com:80"]
    pipeline: '%{[fields.pipeline]}'
    bulk_max_body_size: 10M
    bulk_max_size: 50
    indices:
      - index: "kafka-logs-%{+yyyy.MM.dd}"
#        pipeline: parse_kafka_log
        template:
          - name: kafka-logs-template
          - path: kafka-logs.template.json